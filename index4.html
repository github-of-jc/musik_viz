<!-- var rotate = 0; var canvas = document.getElementById('tutorial2'); //check for
browser support for
<canvas>
  element if (canvas.getContext) { //get drawing context var ctx =
  canvas.getContext('2d'); draw(); } function draw() { updateAnimation();
  ctx.clearRect(0, 0, canvas.width, canvas.height); var width = 100, height =
  100; ctx.save(); ctx.translate(canvas.width/2, canvas.height/2); /*
  ctx.rotate(rotate); console.log(rotate); ctx.beginPath(); ctx.arc(0,0, 75, 0,
  2*Math.PI, false); ctx.fill(); */ var rotate2 = 0; numBeam = 100 for( var i =
  0; i < numBeam; i++) { ran = Math.random() * numBeam ctx.save(); ctx.fillStyle
  = "red" ctx.rotate(rotate2); ctx.translate(50, 0); //50 is radius of center
  ctx.fillRect(0,0,ran,2); ctx.restore(); rotate2 += (2*Math.PI) / numBeam; }
  ctx.restore(); setTimeout(draw, 25); } function updateAnimation() { rotate +=
  Math.PI / 200; // rotate } -->

  <html>
    <head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
      <title>capture microphone audio into buffer</title>

      <script type="text/javascript">
        function myFunction() {
            var rotate = 0;
          var audioContext = new AudioContext();
          var analyserNode = audioContext.createAnalyser();

          var canvas = document.getElementById('canvas');
          const ctx = canvas.getContext('2d');
          var WIDTH = 500;
          var HEIGHT = 500;

          console.log('audio is starting up ...');

          var BUFF_SIZE = 1024;

          var audioInput = null,
            microphone_stream = null,
            gain_node = null,
            script_processor_node = null,
            script_processor_fft_node = null,
            analyserNode = null;

          if (!navigator.getUserMedia)
            navigator.getUserMedia =
              navigator.getUserMedia ||
              navigator.webkitGetUserMedia ||
              navigator.mozGetUserMedia ||
              navigator.msGetUserMedia;

          if (navigator.getUserMedia) {
            navigator.getUserMedia(
              {audio: true},
              function (stream) {
                start_microphone(stream);
              },
              function (e) {
                alert('Error capturing audio.');
              }
            );
          } else {
            alert('getUserMedia not supported in this browser.');
          }

          // ---

          function show_some_data(
            given_typed_array,
            num_row_to_display,
            label
          ) {
            // given_typed_array is the array with numbers
            console.log('given_typed_array');
            console.log(given_typed_array);
            var size_buffer = given_typed_array.length;
            console.log(size_buffer);
            var index = 0;
            var max_index = num_row_to_display;
            console.log(max_index);

            console.log('__________ ' + label);
            const star = '*';
            result = document.getElementById('result');
            result.innerHTML = null;

            function updateAnimation() { rotate +=
  Math.PI / 200;  }

            function draw() {
              drawVisual = requestAnimationFrame(draw);
              analyser = analyserNode;
              analyser.getByteTimeDomainData(given_typed_array);

              updateAnimation();
              ctx.clearRect(0, 0, canvas.width, canvas.height);
              var width = 100,
                height = 100;

              ctx.save();
              ctx.translate(canvas.width / 2, canvas.height / 2);

              /* ctx.rotate(rotate);
    console.log(rotate);
    ctx.beginPath();
    ctx.arc(0,0, 75, 0, 2*Math.PI, false);
    ctx.fill(); */

    var rotate2 = 0;
  numBeam = size_buffer/10
  for (var i = 0; i < numBeam; i++) {
    ran = given_typed_array[i] /5
    console.log(ran);
    ctx.save();
    if (i % 2 == 0) 
    {ctx.fillStyle = "pink";}
    else{ctx.fillStyle = "blue";}
    ctx.rotate(rotate2);
    ctx.translate(50, 20); //x is radius of center
    ctx.fillRect(0, 0, 2, Math.pow(ran, 1.5));
    ctx.restore();
    rotate2 += (2 * Math.PI) / numBeam;
  }
              ctx.restore();

            }

            draw();
          }

          function process_microphone_buffer(event) {
            // invoked by event loop

            var i, N, inp, microphone_output_buffer;

            microphone_output_buffer = event.inputBuffer.getChannelData(0); // just mono - 1 channel for now
            console.log(microphone_output_buffer);

            // microphone_output_buffer  <-- this buffer contains current gulp of data size BUFF_SIZE

            show_some_data(
              microphone_output_buffer,
              500,
              'from getChannelData'
            );
            document.getElementById('result').innerHTML = null; // flush
          }

          function start_microphone(stream) {
            gain_node = audioContext.createGain();
            gain_node.connect(audioContext.destination);

            microphone_stream = audioContext.createMediaStreamSource(stream);
            microphone_stream.connect(gain_node);

            script_processor_node = audioContext.createScriptProcessor(
              BUFF_SIZE,
              1,
              1
            );
            script_processor_node.onaudioprocess = process_microphone_buffer;

            microphone_stream.connect(script_processor_node);

            // --- enable volume control for output speakers

            document
              .getElementById('volume')
              .addEventListener('change', function () {
                var curr_volume = this.value;
                gain_node.gain.value = curr_volume;

                console.log('curr_volume ', curr_volume);
              });

            // --- setup FFT

            script_processor_fft_node = audioContext.createScriptProcessor(
              2048,
              1,
              1
            );
            script_processor_fft_node.connect(gain_node);

            analyserNode = audioContext.createAnalyser();
            analyserNode.smoothingTimeConstant = 0;
            analyserNode.fftSize = 1024;

            microphone_stream.connect(analyserNode);

            analyserNode.connect(script_processor_fft_node);

            script_processor_fft_node.onaudioprocess = function () {
              // get the average for the first channel
              var array = new Uint8Array(analyserNode.frequencyBinCount);
              analyserNode.getByteFrequencyData(array);

              // draw the spectrogram
              if (
                microphone_stream.playbackState ==
                microphone_stream.PLAYING_STATE
              ) {
                show_some_data(array, 5, 'from fft');
              } else {
                console.log('no spectogram');
              }
            };
          }
        } // webaudio_tooling_obj = function()
      </script>
    </head>
    <body>
      <p>Volume</p>
      <input id="volume" type="range" min="0" max="1" step="0.1" value="0.5" />
      <button onClick="myFunction();">start recording</button>
      <div id="result"></div>
      <div><canvas id="canvas" width="500" height="500"></canvas></div>
    </body>
  </html>
</canvas>
